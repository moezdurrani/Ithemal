{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ITHEMAL_HOME'], 'learning', 'pytorch'))\n",
    "\n",
    "import common_libs.utilities as ut\n",
    "import data.data_cost as dt\n",
    "import functools\n",
    "from pprint import pprint\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Callable, List, NamedTuple\n",
    "\n",
    "SLOT_WIDTH = 32\n",
    "NUM_SLOTS = 8\n",
    "\n",
    "SimulatorInput = NamedTuple('SimulatorInput', [\n",
    "    ('slot_vector', torch.tensor),\n",
    "    ('instruction_vector', torch.tensor),\n",
    "])\n",
    "SimulatorResult = NamedTuple('SimulatorResult', [\n",
    "    ('wait_time', torch.tensor),\n",
    "    ('write_head', torch.tensor),\n",
    "    ('write_state', torch.tensor),\n",
    "    ('write_time', torch.tensor),\n",
    "])\n",
    "ModelRunResult = NamedTuple('ModelRunResult', [\n",
    "    ('prediction', torch.tensor),\n",
    "    ('loss', torch.tensor),\n",
    "    ('slots', List['Slot']),\n",
    "])\n",
    "\n",
    "class Slot(object):\n",
    "    def __init__(self):\n",
    "        # type: () -> None\n",
    "        self.state = torch.randn(SLOT_WIDTH)\n",
    "        self.remaining_time = torch.zeros(1)\n",
    "\n",
    "    def mutate(self, new_state, additional_time):\n",
    "        # type: (torch.tensor, torch.tensor) -> torch.tensor\n",
    "        self.state = self.state * (self.remaining_time > 0).float() + new_state\n",
    "        old_time = self.remaining_time\n",
    "        self.remaining_time = self.remaining_time + additional_time\n",
    "        return old_time[0]\n",
    "\n",
    "    def step(self, time):\n",
    "        # type: (torch.tensor) -> None\n",
    "        self.remaining_time = torch.clamp(self.remaining_time - time, min=0)\n",
    "\n",
    "    def read(self):\n",
    "        # type: () -> torch.tensor\n",
    "        return torch.cat([self.remaining_time, self.state * (self.remaining_time > 0).float()])\n",
    "\n",
    "def cat_embedder(emb_dim, max_n_srcs, max_n_dsts):\n",
    "    # type: (int, int, int) -> Callable[[ut.Instruction], torch.tensor]\n",
    "    sym_dict, _ = ut.get_sym_dict()\n",
    "    embedder = torch.nn.Embedding(len(sym_dict), emb_dim)\n",
    "    clamp = lambda x: x if x < len(sym_dict) else len(sym_dict) - 1\n",
    "\n",
    "    def get_emb_list(arr, length):\n",
    "        # type: (List[int], int) -> List[torch.tensor]\n",
    "        assert len(arr) <= length\n",
    "        real = [embedder(torch.tensor(clamp(val))) for val in arr]\n",
    "        zeros = [torch.zeros(emb_dim) for _ in range(length - len(arr))]\n",
    "        return real + zeros\n",
    "\n",
    "    def embed(instr):\n",
    "        # type: (ut.Instruction) -> torch.tensor\n",
    "        opc = embedder(torch.tensor(instr.opcode))\n",
    "        srcs = get_emb_list(instr.srcs, max_n_srcs)\n",
    "        dsts = get_emb_list(instr.dsts, max_n_dsts)\n",
    "        return torch.cat([opc] + srcs + dsts)\n",
    "\n",
    "    return embed\n",
    "\n",
    "\n",
    "class NeuralProcessorSimulator(nn.Module):\n",
    "    def __init__(self):\n",
    "        # type: () -> None\n",
    "        super(NeuralProcessorSimulator, self).__init__()\n",
    "        self.embedder = cat_embedder(128, 3, 3)\n",
    "        self.instr_vec_emb = nn.Linear(128*7, 128)\n",
    "        self.slot_vec_emb = nn.Linear((1+SLOT_WIDTH)*NUM_SLOTS, 128)\n",
    "        self.wait_time_out = nn.Linear(256, 1)\n",
    "        self.write_head_out = nn.Linear(256, NUM_SLOTS)\n",
    "        self.write_state_out = nn.Linear(256, SLOT_WIDTH)\n",
    "        self.write_time_out = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, instr_vec, slot_vec):\n",
    "        # type: (torch.tensor, torch.tensor) -> SimulatorResult\n",
    "        instr_vec = F.relu(self.instr_vec_emb(instr_vec))\n",
    "        slot_vec = F.relu(self.slot_vec_emb(slot_vec))\n",
    "        concat = torch.cat([instr_vec, slot_vec])\n",
    "\n",
    "        wait_time = self.wait_time_out(concat).abs()\n",
    "        write_head = F.softmax(self.write_head_out(concat), dim=0)\n",
    "        write_state = self.write_state_out(concat)\n",
    "        write_time = self.write_time_out(concat).abs()\n",
    "\n",
    "        return SimulatorResult(\n",
    "            wait_time=wait_time,\n",
    "            write_head=write_head,\n",
    "            write_state=write_state,\n",
    "            write_time=write_time,\n",
    "        )\n",
    "\n",
    "def run_on_data(model, block, actual, debug=False):\n",
    "    # type: (nn.Module, ut.BasicBlock, float, bool) -> ModelRunResult\n",
    "    slots = [Slot() for _ in range(NUM_SLOTS)]\n",
    "    schedule_loss = torch.tensor(0.)\n",
    "    wait_time = torch.tensor(0.)\n",
    "\n",
    "    for instr in block.instrs:\n",
    "        slot_vec = torch.cat([slot.read() for slot in slots])\n",
    "        instr_vec = model.embedder(instr)\n",
    "        result = model(instr_vec, slot_vec)\n",
    "\n",
    "        if debug:\n",
    "            print(instr)\n",
    "            pprint(dict(vars(SimulatorResult(*[x.data for x in result]))))\n",
    "            print()\n",
    "\n",
    "        wait_time = wait_time + result.wait_time[0]\n",
    "        for slot in slots:\n",
    "            slot.step(result.wait_time)\n",
    "\n",
    "        for i in range(NUM_SLOTS):\n",
    "            frac = result.write_head[i]\n",
    "            overfill_loss = slots[i].mutate(frac * result.write_state, frac * result.write_time)\n",
    "            schedule_loss = schedule_loss + frac * overfill_loss\n",
    "            schedule_loss = schedule_loss + (frac > 1e-2).float() # l0 loss\n",
    "\n",
    "    remaining_time = torch.max(torch.cat([slot.remaining_time for slot in slots]))\n",
    "    total_time = wait_time + remaining_time\n",
    "    wrongness_loss = F.mse_loss(total_time, torch.tensor(actual))\n",
    "    loss = schedule_loss + 10 * wrongness_loss\n",
    "    return ModelRunResult(total_time, loss, slots)\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, model, train_data, name, save_freq=600):\n",
    "        # type: (nn.Module, List[dt.DataItem], str, float) -> None\n",
    "        self.model = model\n",
    "        self.train_data = train_data\n",
    "        self.name = name\n",
    "        self.save_freq = save_freq\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay=1e-5)\n",
    "        self.last_save_time = 0 # type: float\n",
    "        self.err_ema = 1\n",
    "\n",
    "    def save_model(self):\n",
    "        # type: () -> None\n",
    "        fname = '{}_{}'.format(self.name, time.time())\n",
    "        fpath =  os.path.join(os.environ['ITHEMAL_HOME'], 'learning', 'pytorch', 'saved', fname)\n",
    "        torch.save(self.model.state_dict(), fpath)\n",
    "\n",
    "    def load_latest(self):\n",
    "        # type: () -> None\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def step_sgd(self, debug=False):\n",
    "        # type: (bool) -> float\n",
    "        scale = 100\n",
    "\n",
    "        if time.time() - self.last_save_time > self.save_freq:\n",
    "            self.save_model()\n",
    "            self.last_save_time = time.time()\n",
    "\n",
    "        datum = random.choice(self.train_data)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        result = run_on_data(self.model, datum.block, datum.y / scale, debug=debug)\n",
    "        result.loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        pred = result.prediction.item() * scale\n",
    "\n",
    "        err = 2 * abs((datum.y - pred) / (datum.y + pred))\n",
    "        self.err_ema = 0.999 * self.err_ema + 0.001 * err\n",
    "\n",
    "        return err\n",
    "\n",
    "    def loop_sgd(self, freq):\n",
    "        # type: () -> None\n",
    "        i = 0\n",
    "        while True:\n",
    "            err = self.step_sgd()\n",
    "            i += 1\n",
    "            if i > freq:\n",
    "                print('err_ema: {:.2f}, err: {:.2f}'.format(self.err_ema, err), end='\\r')\n",
    "                i = 0\n",
    "\n",
    "    def debug_sgd(self):\n",
    "        # type: () -> None\n",
    "        err = self.step_sgd(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.environ['ITHEMAL_HOME'], 'learning', 'pytorch')\n",
    "data = dt.load_dataset(\n",
    "    os.path.join(root, 'inputs', 'embeddings', 'code_delim.emb'),\n",
    "    os.path.join(root, 'saved', 'time_skylake_1217.data')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nps = NeuralProcessorSimulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(nps, data.train, 'nps_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nps\n",
    "datum = random.choice(data.train)\n",
    "block = datum.block\n",
    "actual = datum.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slots = [Slot() for _ in range(NUM_SLOTS)]\n",
    "schedule_loss = torch.tensor(0.)\n",
    "wait_time = torch.tensor(0.)\n",
    "\n",
    "for instr in block.instrs:\n",
    "    slot_vec = torch.cat([slot.read() for slot in slots])\n",
    "    instr_vec = model.embedder(instr)\n",
    "    result = model(instr_vec, slot_vec)\n",
    "\n",
    "    print(instr)\n",
    "    pprint(dict(vars(SimulatorResult(*[x.data for x in result]))))\n",
    "    print()\n",
    "\n",
    "    wait_time = wait_time + result.wait_time[0]\n",
    "    for slot in slots:\n",
    "        slot.step(result.wait_time)\n",
    "\n",
    "    for i in range(NUM_SLOTS):\n",
    "        frac = result.write_head[i]\n",
    "        overfill_loss = slots[i].mutate(frac * result.write_state, frac * result.write_time)\n",
    "        schedule_loss = schedule_loss + frac * overfill_loss\n",
    "        schedule_loss = schedule_loss + (frac > 1e-2).float() # l0 loss\n",
    "\n",
    "remaining_time = torch.max(torch.cat([slot.remaining_time for slot in slots]))\n",
    "total_time = wait_time + remaining_time\n",
    "wrongness_loss = F.mse_loss(total_time, torch.tensor(actual))\n",
    "loss = schedule_loss + 10 * wrongness_loss\n",
    "res = ModelRunResult(total_time, loss, slots)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.step_sgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import psutil\n",
    "\n",
    "def memReport():\n",
    "    num_obj = 0\n",
    "    for obj in gc.get_objects():\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            num_obj += 1\n",
    "    print('num_obj: {}'.format(num_obj))\n",
    "\n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "\n",
    "memReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nps.write_time_out.bias.grad"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
