{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ITHEMAL_HOME'], 'learning', 'pytorch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import data.data_cost as dt\n",
    "import common_libs.utilities as ut\n",
    "import models.train as tr\n",
    "import models.graph_models as md\n",
    "import models.losses as ls\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt.load_dataset('/home/ithemal/ithemal/learning/pytorch/inputs/embeddings/code_delim.emb', data_savefile='/home/ithemal/ithemal/learning/pytorch/saved/time_skylake_1217.data')\n",
    "\n",
    "ys = np.array([d.y for d in data.train])\n",
    "mean = ys.mean()\n",
    "std = ys.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = data.final_embeddings.shape[1]\n",
    "model = md.GraphNN(embedding_size, 256, 1, False)\n",
    "model.set_learnable_embedding(mode = 'none', dictsize = max(data.word2id) + 1, seed = data.final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tr.Train(model, data, 4)\n",
    "train.loss_fn = ls.mse_loss\n",
    "train.print_fn = train.print_final\n",
    "train.correct_fn = train.correct_regression\n",
    "train.num_losses = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('../saved/edges_none_01-07-19_06:42:33.mdl')\n",
    "model.load_state_dict(state_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(item):\n",
    "    item.block.remove_edges()\n",
    "    for i in item.block.instrs:\n",
    "        print(i)\n",
    "    prediction = model(data.train[0]).item()\n",
    "    actual = item.y\n",
    "    print('P: {:.2f}, A: {:.2f}'.format(prediction, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data.data:\n",
    "    item.block.remove_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted = train.validate('/tmp/foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = data.test[30]\n",
    "\n",
    "model.remove_refs(item)\n",
    "model.init_bblstm(item)\n",
    "roots = item.block.find_roots()\n",
    "\n",
    "root_hidden = []\n",
    "for instr in roots:\n",
    "    token_embeds_lstm = torch.FloatTensor(instr.tokens).unsqueeze(1)\n",
    "    _, (ins_embed, _) = model.lstm_token(token_embeds_lstm, model.init_hidden())\n",
    "    _, (ins_hidden, _) = model.lstm_ins(ins_embed, model.init_hidden())\n",
    "    root_hidden.append(ins_hidden.squeeze())\n",
    "\n",
    "final_hidden = root_hidden[0]\n",
    "for hidden in root_hidden[1:]:\n",
    "    final_hidden = model.reduction(final_hidden,hidden)\n",
    "pred = model.linear(final_hidden).squeeze()\n",
    "\n",
    "total_weight = model.linear.weight.data.squeeze().abs().sum()\n",
    "\n",
    "for i in range(len(root_hidden)):\n",
    "    max_vals, max_idxs = torch.stack(root_hidden).max(dim=0)\n",
    "    idxs = np.where(max_idxs.data.numpy() == i)\n",
    "    i_vals = max_vals[idxs]\n",
    "    i_weights = model.linear.weight.data.squeeze()[idxs]\n",
    "    i_w_contrib = (i_weights * i_vals).sum()\n",
    "    print('{:<30}: weight {:.2f}, total contrib {:.2f}'.format(\n",
    "        item.block.instrs[i],\n",
    "        i_weights.abs().sum() / total_weight,\n",
    "        i_w_contrib,\n",
    "    ))\n",
    "\n",
    "print('\\npred: {:.2f}, actual: {:.2f}'.format(\n",
    "    pred.item(),\n",
    "    item.y,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset = data.train\n",
    "\n",
    "starts = [None] * len(dataset)\n",
    "ends = [None] * len(dataset)\n",
    "\n",
    "for i, datum in enumerate(dataset):\n",
    "    starts[i] = datum.y * 0.75\n",
    "    ends[i] = datum.y * 1.25\n",
    "\n",
    "starts.sort()\n",
    "ends.sort()\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "max_val = 0\n",
    "max_count = 0\n",
    "curr_count = 0\n",
    "for val, typ in sorted(itertools.chain(zip(starts, itertools.repeat('start')), zip(ends, itertools.repeat('end')))):\n",
    "    if typ == 'start':\n",
    "        curr_count += 1\n",
    "        if curr_count > max_count:\n",
    "            max_count = curr_count\n",
    "            max_val = val\n",
    "    elif typ == 'end':\n",
    "        curr_count -= 1\n",
    "    xs.append(val)\n",
    "    ys.append(curr_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_2 = np.ones_like(actual) * 33 + 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(actual - p_2) / (p_2 + 1e-3) * 100 < 25)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
